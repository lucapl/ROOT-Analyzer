{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROOT analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import json\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.viz.graphs import *\n",
    "from src.viz.images import *\n",
    "from src.utils import *\n",
    "from src.file_reading import *\n",
    "from src.detection.elements import *\n",
    "from src.getFirstFrame import *\n",
    "\n",
    "from sklearn.mixture import GaussianMixture,BayesianGaussianMixture\n",
    "\n",
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_imshow = lambda img: scaled_imshow(img,fx=0.8,fy=0.8)\n",
    "simshow = lambda img: scaled_imshow(img,fx=0.3,fy=0.3)\n",
    "mini_imshow = lambda img: scaled_imshow(img,fx=0.2,fy=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = lambda i: f\"clip_{i}\"\n",
    "clip_mp4 = lambda i: f\"{clip(i)}.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_orange = np.array([0, 100, 100])\n",
    "orange = (48,91,198)\n",
    "upper_orange = np.array([20, 255, 255])\n",
    "lower_dark_blue = np.array([100, 50, 50])\n",
    "blue = (92,38,15)\n",
    "upper_dark_blue = np.array([140, 255, 255])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = lambda a_1,a_2: np.mean((np.array(a_1)-np.array(a_2))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_max_color_diff = mse((0,0,0),(255,255,255))\n",
    "def color_sim(a_1,a_2):\n",
    "    return 1 - (mse(a_1,a_2)/_max_color_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input data is be divided into 3 groups depending on the difficulty for example:\n",
    "- easy: perfect top down view, the game elements are not covered with hands when carrying them, the lighting is good\n",
    "- medium: strong light at the side causing shadows,\n",
    "- difficult: same as medium + a slightly angled camera, hands covering the pieces\n",
    "\n",
    "There are 3 clips per difficulty. The data is located in a [google drive]((https://drive.google.com/drive/folders/1VrQ98TC5jPmWk1QYr3lUP3SGk_3_AEmx?usp=sharing))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \".\\\\data\\\\\"\n",
    "difficulties = [\"easy\",\"medium\",\"hard\"]\n",
    "clip_dirs = dict([(diff,data_dir+diff+\"\\\\\") for diff in difficulties])\n",
    "resized_clip_dirs = dict([(diff,data_dir+diff+f\"\\\\resized\\\\\") for diff in difficulties])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_frames = dict([(diff,getFirstFrame(_dir+clip_mp4(0))) for diff,_dir in clip_dirs.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_imshow(first_frames[\"easy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_imshow(first_frames[\"medium\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_imshow(first_frames[\"hard\"]) # TODO rotate hard clips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also resized clips to speed up working time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_first_frames = dict([(diff,getFirstFrame(_dir+clip_mp4(0))) for diff,_dir in resized_clip_dirs.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simshow(np.concatenate([resized_first_frames[diff] for diff in difficulties],axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game is played between 2 factions: Eyrie Dynasties (blue birds), Marquise de Cat (orange cats). The board is a Winter Map. Because the clearings in the forest are barely differentiable, a mask was created to help with detecting static elements of the board. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_data_dir = data_dir+\"game_data\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_mask = cv.imread(game_data_dir+\"board_mask.png\")\n",
    "\n",
    "simshow(board_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The red indicates the where the score track is. \n",
    "- The green defines where craftable items are.\n",
    "- The blue shows where the clearing approximately are, with the black squares showing where building spaces are.\n",
    "\n",
    "JSON was created to define paths on the map, done purely for drawing a graph of the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/game_data/board_info.json\", \"r\") as info_file:\n",
    "    board_info = json.load(info_file)\n",
    "\n",
    "    draw_map(board_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help with detection a print and play set is used with all the elements taken from [PnP PARADISE](https://www.pnpparadise.com/set1/root)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_ref = read_pdf(data_dir+'game_data\\\\board.pdf')\n",
    "\n",
    "simshow(board_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Milestone 1\n",
    "\n",
    "In this phase, the following things were detected:\n",
    "- the black dice tray along with the dice on it\n",
    "- the board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dice tray detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = first_frames[\"easy\"]\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dice tray is all black so a simple threshold was performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tray_cont,dice1_cont,dice2_cont,img_cont = detect_dice_tray(img)\n",
    "mini_imshow(img_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tray = crop_contour(img,tray_cont)\n",
    "\n",
    "dice1 = crop_contour(img,dice1_cont)\n",
    "dice2 = crop_contour(img,dice2_cont)\n",
    "\n",
    "mini_imshow(tray)\n",
    "imshow(dice1)\n",
    "imshow(dice2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Board detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting the board was harder as it has much more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_ref = read_pdf('.\\\\data\\\\game_data\\\\board.pdf')\n",
    "board_gray = cv.GaussianBlur(cv.cvtColor(board_ref, cv.COLOR_BGR2GRAY),(7,7),0)\n",
    "\n",
    "simshow(board_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To achieve this steps descriptors are used, in particular the SIFT detector. To quickly match the descriptors FLANN algorithm is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M,drawn_matches,board_cont = descriptor_detect(img,board_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simshow(drawn_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(image, angle):\n",
    "  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "  result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_board = crop_contour(img,board_cont)\n",
    "crop_board = rotate_image(crop_board,0.8)\n",
    "simshow(crop_board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code doesn't have to be run much, because the board should not a lot move in the clips\n",
    "\n",
    "In the milestone 1, there were also attempts to segment the image using a Gaussian Mixture, but they were quite slow and not effective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Progress\n",
    "\n",
    "### Tracking Game Score\n",
    "\n",
    "Game score is tracked in the lower half of the board, by blue and orange counters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimask = crop_contour(cv.warpPerspective(board_mask, M, (img.shape[1], img.shape[0])),board_cont)\n",
    "trimask = rotate_image(trimask,1)\n",
    "simshow(trimask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_mask,clearing_mask,score_mask = trimask[:,:,1],trimask[:,:,0],trimask[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_score = crop_contour(crop_board,score_mask)\n",
    "simshow(crop_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cells(img,mask,thresh_arg=(55,15),hor_ker=np.ones((1,40)),ver_ker=np.ones((30,1)),hor_ver_ker=np.ones((7,7))):\n",
    "    mask_cont = cv.findContours(mask,cv.RETR_TREE,cv.CHAIN_APPROX_SIMPLE)[0][0]\n",
    "    cropped = crop_contour(img,mask_cont)\n",
    "    gray = cv.cvtColor(cropped,cv.COLOR_BGR2GRAY)\n",
    "    imshow(cropped)\n",
    "    threshold = cv.adaptiveThreshold(\n",
    "        gray,\n",
    "        255,\n",
    "        cv.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv.THRESH_BINARY,\n",
    "        *thresh_arg\n",
    "    )\n",
    "    imshow(threshold)\n",
    "\n",
    "    hor=255-cv.erode(cv.dilate(threshold,hor_ker),hor_ker)\n",
    "    ver=255-cv.erode(cv.dilate(threshold,ver_ker),ver_ker)\n",
    "    hor_ver = cv.morphologyEx(hor+ver,cv.MORPH_CLOSE,hor_ver_ker)\n",
    "    imshow(hor_ver)\n",
    "    return hor_ver,mask_cont\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cell_contours(hor_ver):\n",
    "    contours,hierarchy = cv.findContours(hor_ver,cv.RETR_TREE,cv.CHAIN_APPROX_SIMPLE)\n",
    "    i,_ = max(enumerate(contours), key=lambda i_c:cv.contourArea(i_c[1]))\n",
    "\n",
    "    cells = []\n",
    "    _,_,child,_ = hierarchy[0][i]\n",
    "    j = child\n",
    "    while True:\n",
    "        _next,_,_,_ = hierarchy[0][j]\n",
    "        cells.append(j)\n",
    "        j = _next\n",
    "        if _next == -1:\n",
    "            break\n",
    "    \n",
    "    return cells,contours\n",
    "\n",
    "    #imshow(cv.drawContours(img_contours,[largest_contour],-1,(0,0,255),2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_ver,score_cont = find_cells(board_ref,board_mask[:,:,2])\n",
    "score_x,score_y,_,_=cv.boundingRect(score_cont)\n",
    "test_score_crop = crop_contour(board_ref,score_cont)\n",
    "cells,cell_cont = find_cell_contours(hor_ver)\n",
    "score_contours = [cell_cont[i] for i in cells[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_scr_cont = [cont + [score_x,score_y] for cont in score_contours]\n",
    "def warp_contours(contours,M):\n",
    "    return [cv.perspectiveTransform(cont.astype(np.float64),M).astype(np.int32) for cont in contours]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warp_scr_cont = warp_contours(abs_scr_cont,M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brc=np.copy(img)\n",
    "simshow(cv.drawContours(brc,warp_scr_cont,-1,(255,0,0),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(img,warp_scr_cont):\n",
    "    blue_score = None\n",
    "    orange_score = None\n",
    "    for cont in warp_scr_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(crop_contour(img,warp_scr_cont[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_color_percentage(image, lower_color, upper_color):\n",
    "    # Convert the image to the HSV color space (Hue, Saturation, Value)\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Create a binary mask for the specified color range\n",
    "    color_mask = cv2.inRange(hsv_image, lower_color, upper_color)\n",
    "\n",
    "    # Calculate the percentage of non-zero pixels in the mask\n",
    "    total_pixels = np.prod(color_mask.shape)\n",
    "    colored_pixels = np.count_nonzero(color_mask)\n",
    "    percentage = (colored_pixels / total_pixels) * 100\n",
    "\n",
    "    return percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_color_percentage(crop_contour(img,warp_scr_cont[0]),lower_dark_blue,upper_dark_blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_color_percentage(crop_contour(img,warp_scr_cont[0]),lower_orange,upper_orange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse(orange,[  5.460956,  46.703438, 105.51114 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_contours(contours,fx=0.25,fy=0.25):\n",
    "    resized = []\n",
    "    for contour in contours:\n",
    "        resized_contour = np.copy(contour)\n",
    "        resized_contour[:, :, 0] = contour[:, :, 0] * fx\n",
    "        resized_contour[:, :, 1] = contour[:, :,  1] * fy\n",
    "        resized.append(resized_contour)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for cont in warp_scr_cont:\n",
    "#     cont\n",
    "#     im = crop_contour(img,cont)\n",
    "#     mean_c = np.mean(im, axis=(0, 1))\n",
    "#     print(mean_c)\n",
    "#     print(mse(mean_c,orange))\n",
    "#     print(mse(mean_c,blue))\n",
    "#     imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking Card Pile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card = read_pdf(game_data_dir+\"card_reverse.pdf\")\n",
    "imshow(card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M,drawn_matches,card_cont = descriptor_detect(img,card,distance=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_imshow(drawn_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_card = crop_contour(img,card_cont)\n",
    "imshow(crop_card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_dir = \".\\\\ignore\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy = cv.VideoCapture(resized_clip_dirs[\"easy\"]+clip_mp4(0))\n",
    "if easy.isOpened():\n",
    "    print(\"Video loaded\")\n",
    "\n",
    "width,height = int(easy.get(3)), int(easy.get(4))\n",
    "\n",
    "print(width, height)\n",
    "\n",
    "fps = easy.get(cv2.CAP_PROP_FPS)\n",
    "print(fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours_to_track = [card_cont,dice1_cont,dice2_cont]\n",
    "static_contours = [board_cont,card_cont]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 648\n",
    "easy.set(cv.CAP_PROP_POS_FRAMES,start)\n",
    "ret, frame = easy.read()\n",
    "# x, y, w, h = cv.boundingRect(resized_contour)\n",
    "# track_window = (x, y, w, h)\n",
    "# roi = frame[y : y + h, x : x + w]\n",
    "\n",
    "# hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "# mask = cv2.inRange(\n",
    "#     hsv_roi, np.array((0.0, 60.0, 32.0)), np.array((180.0, 255.0, 255.0))\n",
    "# )\n",
    "# roi_hist = cv2.calcHist([hsv_roi], [0], mask, [180], [0, 180])\n",
    "# cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "# term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_track = resize_contours(contours_to_track)\n",
    "static = resize_contours(static_contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbox(frame, bbox, color=(255, 255, 255)):\n",
    "    p1 = (int(bbox[0]), int(bbox[1]))\n",
    "    p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "    cv2.rectangle(frame, p1, p2, color, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track = cv.VideoWriter(\n",
    "    f\".\\\\ignore\\\\{clip(0)}.avi\",\n",
    "    cv.VideoWriter_fourcc(*\"DIVX\"),\n",
    "    fps,\n",
    "    (width, height),\n",
    ")\n",
    "\n",
    "# card_tracker = cv.TrackerMIL_create()\n",
    "# card_tracker.init(frame,cv.boundingRect(resized_contour))\n",
    "trackers = [create_tracker(\"CSRT\") for _ in to_track]\n",
    "for tracker,contour in zip(trackers,to_track):\n",
    "    tracker.init(frame,cv.boundingRect(contour))\n",
    "\n",
    "easy.set(cv.CAP_PROP_POS_FRAMES,start)\n",
    "sec = 5\n",
    "i = 0\n",
    "for _ in tqdm(range(int(sec*fps))):\n",
    "    if not easy.isOpened():\n",
    "        break\n",
    "    if i > sec*fps:\n",
    "        break\n",
    "\n",
    "    ret, frame = easy.read()\n",
    "    raw_frame = np.copy(frame)\n",
    "\n",
    "    if ret:\n",
    "        for cont in static:\n",
    "            draw_bbox(frame, cv.boundingRect(cont), (255, 0, 0))\n",
    "\n",
    "        for tracker in trackers:\n",
    "            ok, bbox = tracker.update(raw_frame)\n",
    "            if ok:\n",
    "                draw_bbox(frame, bbox, (0, 255, 0))\n",
    "            else:\n",
    "                frame = cv2.putText(frame, 'FAILED', (0,0), cv.FONT_HERSHEY_SIMPLEX,  \n",
    "                1, (0,0,255), 2, cv2.LINE_AA) \n",
    "        # hsv = cv.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        # dst = cv.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
    "        # ret, track_window = cv.CamShift(dst, track_window, term_crit)\n",
    "        # pts = np.int0(cv.boxPoints(ret))\n",
    "        track.write(frame)\n",
    "        i+=1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "track.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -hide_banner -loglevel error -i .\\ignore\\clip_0.avi -y .\\ignore\\clip_0.mp4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
